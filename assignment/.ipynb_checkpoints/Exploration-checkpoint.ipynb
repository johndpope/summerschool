{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration and a Simple Baseline\n",
    "\n",
    "In this part of the assignment, we'll introduce the [Stanford Sentiment Treebank](https://nlp.stanford.edu/sentiment/index.html) (SST) dataset, and train a Naive Bayes model as a simple baseline. The SST, introduced by [(Socher et al. 2013)](http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf) consists of approximately 10,000 sentences from movie reviews associated with fine-grained sentiment labels on a five-point scale, and is a popular benchmark for text classification.\n",
    "\n",
    "## Outline\n",
    "\n",
    "- **Part (a):** The Stanford Sentiment Treebank\n",
    "- **Part (b):** Naive Bayes\n",
    "- **Part (c):** Exploring Negation\n",
    "\n",
    "Exercises are interspersed throughout the notebook. Be sure you catch all of them! There are 4 questions for Part (a), 2 for Part (b), and 3 for Part (c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Requirements done!\n"
     ]
    }
   ],
   "source": [
    "# Install a few python packages using pip\n",
    "from common import utils\n",
    "utils.require_package(\"wget\")      # for fetching dataset\n",
    "utils.require_package(\"bokeh\")     # for plotting histograms\n",
    "#utils.require_package(\"graphviz\")  # for rendering trees\n",
    "\n",
    "print('Success! Requirements done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries: GraphViz\n",
    "\n",
    "This notebook uses [GraphViz](https://www.graphviz.org/) to render tree structures. On Ubuntu / Debian (including Google Cloud), you can install it by running on the command line:\n",
    "```\n",
    "sudo apt-get install graphviz\n",
    "```\n",
    "\n",
    "For Mac OSX, you can install using Homebrew:\n",
    "```\n",
    "brew install graphviz\n",
    "```\n",
    "or see https://www.graphviz.org/download/ for more options. Run the cell below to set up rendering and show a sample tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding nltk.tree.Tree pretty-printing to use custom GraphViz.\n",
      "Sample tree to test rendering:\n",
      "          4           \n",
      "      ____|_________   \n",
      "     4              | \n",
      "  ___|_________     |  \n",
      " 2   3         3    3 \n",
      " |   |         |    |  \n",
      " I  love     JSALT  ðŸ˜„ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from common import treeviz\n",
    "import sst\n",
    "# Monkey-patch NLTK with better Tree display that works on Cloud or other display-less server.\n",
    "print(\"Overriding nltk.tree.Tree pretty-printing to use custom GraphViz.\")\n",
    "treeviz.monkey_patch(nltk.tree.Tree, node_style_fn=sst.sst_node_style, format='svg')\n",
    "\n",
    "# Test rendering\n",
    "print(\"Sample tree to test rendering:\")\n",
    "#nltk.tree.Tree.fromstring(\"(4 (4 (2 I) (3 love) (3 JSALT)) (3 ðŸ˜„))\")\n",
    "\n",
    "from nltk.tree import *\n",
    "tree = Tree.fromstring(\"(4 (4 (2 I) (3 love) (3 JSALT)) (3 ðŸ˜„))\")\n",
    "tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"86c6b1a2-488e-4e1e-a098-aacc07c532d6\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"86c6b1a2-488e-4e1e-a098-aacc07c532d6\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"86c6b1a2-488e-4e1e-a098-aacc07c532d6\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '86c6b1a2-488e-4e1e-a098-aacc07c532d6' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.16.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"86c6b1a2-488e-4e1e-a098-aacc07c532d6\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"86c6b1a2-488e-4e1e-a098-aacc07c532d6\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"86c6b1a2-488e-4e1e-a098-aacc07c532d6\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '86c6b1a2-488e-4e1e-a098-aacc07c532d6' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.16.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.16.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.16.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.16.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"86c6b1a2-488e-4e1e-a098-aacc07c532d6\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Imports done!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import os, sys, re, json, time, datetime, shutil\n",
    "import itertools, collections\n",
    "from importlib import reload\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Helper libraries.\n",
    "from common import utils, vocabulary, tf_embed_viz, treeviz\n",
    "from common import patched_numpy_io\n",
    "# Code for this assignment\n",
    "import sst, models, models_test\n",
    "\n",
    "# Bokeh for plotting.\n",
    "import bokeh.plotting as bp\n",
    "from bokeh.models import HoverTool\n",
    "bp.output_notebook()\n",
    "\n",
    "print('Success! Imports done!')\n",
    "# Helper code for plotting histograms\n",
    "def plot_length_histogram(lengths, x_range=[0,100], bins=40, normed=True):\n",
    "    hist, bin_edges = np.histogram(a=lengths, bins=bins, normed=normed, range=x_range)\n",
    "    bin_centers = (bin_edges[1:] + bin_edges[:-1])/2\n",
    "    bin_widths =  (bin_edges[1:] - bin_edges[:-1])\n",
    "\n",
    "    hover = HoverTool(tooltips=[(\"bucket\", \"@x\"), (\"count\", \"@top\")], mode=\"vline\")\n",
    "    fig = bp.figure(plot_width=800, plot_height=400, tools=[hover])\n",
    "    fig.vbar(x=bin_centers, width=bin_widths, top=hist, hover_fill_color=\"firebrick\")\n",
    "    fig.y_range.start = 0\n",
    "    fig.x_range.start = 0\n",
    "    fig.xaxis.axis_label = \"Example length (number of tokens)\"\n",
    "    fig.yaxis.axis_label = \"Frequency\"\n",
    "    bp.show(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part (a): The Stanford Sentiment Treebank\n",
    "\n",
    "_If you haven't yet, be sure to familiarize yourself with the [Prelude notebook](Prelude.ipynb), as this assignment will assume familiarity with the text pre-processing steps described there._\n",
    "\n",
    "The [Stanford Sentiment Treebank](https://nlp.stanford.edu/sentiment/index.html) (SST) is one of the most widely used datasets as a benchmark for text classification. It consists of 11,855 sentences drawn from a corpus of movie reviews (originally from Rotten Tomatoes), each labeled with sentiment on a five-point scale.\n",
    "\n",
    "For example:\n",
    "```\n",
    "sentence: [A warm , funny , engaging film .]\n",
    "label:    4 (very positive)\n",
    "```\n",
    "\n",
    "For this assignment, we'll work with the binarized form of the dataset, where the lowest two classes are mapped to a single \"negative\" label, the highest two are mapped to a single \"positive\" label, and neutral examples are omitted.\n",
    "\n",
    "**Side note:**\n",
    "Unlike most classification datasets, SST is also a _treebank_, which means each sentence is associated with a tree structure that decomposes it into subphrases. So for the example above, we'd also have sentiment labels for `[warm , funny]` and `[engaging film .]` and so on. The trees are created by running the [Stanford Parser](https://nlp.stanford.edu/software/lex-parser.shtml) over the original sentences, then crowdsourcing sentiment labels on each sub-phrase. \n",
    "\n",
    "We'll mostly concern ourselves with the sentence-level (\"root\") labels, but the tree structure will come in handy in two places:\n",
    "- As a way of analyzing the examples to find instances of negation\n",
    "- (optionally) As a source of additional training data, by including phrase labels\n",
    "\n",
    "### Obtaining the Data\n",
    "The data is distributed as serialized trees in [S-expression](https://en.wikipedia.org/wiki/S-expression) form, like this:\n",
    "```\n",
    "(4 (4 (2 A) (4 (3 (3 warm) (2 ,)) (3 funny))) (3 (2 ,) (3 (4 (4 engaging) (2 film)) (2 .))))\n",
    "```\n",
    "\n",
    "We've provided an `SSTDataset` class (in `sst.py`) which will download the dataset and parse the S-expressions into [`nltk.tree.Tree`](http://www.nltk.org/api/nltk.html?highlight=tree#nltk.tree.Tree) objects that you can easily view in the notebook.\n",
    "\n",
    "`SSTDataset` also implements the text-processing pipeline described in the [Prelude notebook](Prelude.ipynb), and provides methods (`as_sparse_bow` and `as_padded_array`) to convert the data to matrix form.\n",
    "\n",
    "Run the cell below; it will download a ~6MB .zip file to the local directory the first time you run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SST from data/sst/trainDevTestTrees_PTB.zip\n",
      "Training set:     8,544 trees\n",
      "Development set:  1,101 trees\n",
      "Test set:         2,210 trees\n",
      "Building vocabulary - 16,474 words\n",
      "Processing to phrases...  Done!\n",
      "Splits: train / dev / test : 98,794 / 13,142 / 26,052\n",
      "Success: Stanford Sentiment Treebank data downloaded!\n"
     ]
    }
   ],
   "source": [
    "import sst\n",
    "ds = sst.SSTDataset(V=20000).process(label_scheme=\"binary\")\n",
    "print('Success: Stanford Sentiment Treebank data downloaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few members of the `SSTDataset()` class that you might find useful:\n",
    "- **`ds.vocab`**: a `vocabulary.Vocabulary` object managing the model vocabulary\n",
    "- **`ds.{train,dev,test}_trees`**: a list of [`nltk.tree.Tree`](http://www.nltk.org/api/nltk.html?highlight=tree#nltk.tree.Tree) objects representing each sentence\n",
    "- **`ds.{train,dev,test}`**: a Pandas DataFrame containing the _processed_ examples, including all subphrases. `label` is the target label, `is_root` denotes whether this example is a root node (full sentence), and `root_id` is the index of the tree that the example was derived from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   4                            \n",
      "           ________|_________________            \n",
      "          4                          3          \n",
      "  ________|___           ____________|___        \n",
      " |            4         |                3      \n",
      " |         ___|____     |             ___|____   \n",
      " |        3        |    |            4        | \n",
      " |    ____|___     |    |      ______|___     |  \n",
      " 2   3        2    3    2     4          2    2 \n",
      " |   |        |    |    |     |          |    |  \n",
      " A  warm      ,  funny  ,  engaging     film  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at samples in your dev set\n",
    "ds.dev\n",
    "\n",
    "# Look at a tree for a positive review (change the index to explore more!)\n",
    "tree = ds.dev_trees[3]\n",
    "tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0                                                    \n",
      "  _______|_____________                                        \n",
      " |                     2                                      \n",
      " |        _____________|____________________________________   \n",
      " |       2                                                  | \n",
      " |    ___|_____________                                     |  \n",
      " |   |                 0                                    | \n",
      " |   |    _____________|__________                          |  \n",
      " |   |   |                        1                         | \n",
      " |   |   |       _________________|______                   |  \n",
      " |   |   |      |                        0                  | \n",
      " |   |   |      |           _____________|________          |  \n",
      " |   |   |      |          1                      2         | \n",
      " |   |   |      |       ___|______            ____|____     |  \n",
      " 2   2   2      2      2          0          2         2    2 \n",
      " |   |   |      |      |          |          |         |    |  \n",
      " It  's like watching  a      nightmare     made     flesh  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at a tree for a negative review\n",
    "tree = ds.dev_trees[361]\n",
    "tree.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (a) questions: Exploring the Data\n",
    "\n",
    "Let's explore the data a bit, to get a sense of what we're working with. If you're not familiar with DataFrames, you may wish to review the Pandas documentation: https://pandas.pydata.org/pandas-docs/stable/dsintro.html \n",
    "\n",
    "Answer the following questions in the cells below:\n",
    "\n",
    "1. Looking at only the root examples in the training set (*Hint: use `ds.train[ds.train.is_root]`*), what is the fraction of positive labels? Is the classification task balanced, or close to it? If we used most-common-class as a baseline classifier, what would the accuracy be?\n",
    "2. What are the five most common words in the dataset? (*Hint: there are several ways to get at this - you might use `collections.Counter`, or poke around in the `ds.vocab` object.*)\n",
    "3. Use the `plot_length_histogram` function (defined above) to plot a histogram of the sentence lengths. What is the 95% percentile length? (i.e. 95% of examples in the training set should be shorter than this)\n",
    "4. Repeat 3., but this time including all subphrases. Notice the difference in distributions. Could this be problematic, if we include subphrases in our training data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers for Part (a)\n",
    "<a id=\"answers_a1234\"></a>\n",
    "\n",
    "1. _Your answer here!_\n",
    "2. _Your answer here!_\n",
    "3. _Your answer here!_\n",
    "4. _Your answer here!_\n",
    "\n",
    "Use the cells below for your code solutions. Each part shouldn't require more than a couple lines, but you're welcome to explore more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "# Code for Part (a).1\n",
    "\n",
    "#### END(YOUR CODE) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "# Code for Part (a).2\n",
    "\n",
    "#### END(YOUR CODE) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "# Code for Part (a).3\n",
    "\n",
    "\n",
    "#### END(YOUR CODE) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "# Code for Part (a).4\n",
    "\n",
    "\n",
    "#### END(YOUR CODE) ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part (b): Naive Bayes\n",
    "\n",
    "In this section, we'll build and explore a Naive Bayes model as a baseline classifier for our dataset.\n",
    "\n",
    "Naive Bayes is perhaps the simplest possible classification algorithm, but it's one that still surprisingly effective for many text classification problems. Recall from your Machine Learning course:\n",
    "\n",
    "$$ P(y = k) = \\hat{\\theta}_k = \\frac{1}{N}\\sum_{i = 1}^N \\mathbf{1}[y_i = k] $$\n",
    "\n",
    "$$ P(x_j | y = 1) = \\hat{\\theta}_{k,j} = \n",
    "\\frac{ \n",
    "\\sum_{i = 1}^N  \\sum_{j' = 1}^{n_i} \\mathbf{1}[y_i = 1 \\wedge x_{j'} = j]\n",
    "}{\n",
    "\\sum_{i = 1}^N  \\mathbf{1}[y_i = 1] \\cdot n_i\n",
    "}\n",
    "$$\n",
    "\n",
    "where $N$ is the size of the dataset, and $n_i$ is the length (number of tokens of the $i^{th}$ example. Prediction is done by computing the score:\n",
    "\n",
    "$$ \\mathrm{score}(x) = \\log \\left(\\frac{P(y = 1) \\prod_{j=1}^n P(x_j | y = 1)}{P(y = 0) \\prod_{j=1}^n P(x_j | y = 0)}\\right) $$\n",
    "\n",
    "We'll just use the [implementation from scikit-learn](http://scikit-learn.org/stable/modules/naive_bayes.html). Like other scikit-learn classifiers, this expects the input as a `scipy.sparse` matrix. Run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: x = (6920, 16474) sparse, y = (6920,)\n",
      "Test set:     x = (1821, 16474) sparse, y = (1821,)\n"
     ]
    }
   ],
   "source": [
    "# 'csr' stands for \"Compressed Sparse Row\", which is one format\n",
    "# for representing sparse matricies.\n",
    "train_x_csr, train_y = ds.as_sparse_bow(\"train\", root_only=True)\n",
    "test_x_csr,  test_y  = ds.as_sparse_bow(\"test\", root_only=True)\n",
    "print(\"Training set: x = {:s} sparse, y = {:s}\".format(str(train_x_csr.shape), \n",
    "                                                str(train_y.shape)))\n",
    "print(\"Test set:     x = {:s} sparse, y = {:s}\".format(str(test_x_csr.shape), \n",
    "                                                str(test_y.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `root_only=True` parameter - this will return only examples corresponding to whole sentences. If you set this to false, you can get examples for all phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (b) Questions\n",
    "\n",
    "Answer the following questions in the answer and code cells below.\n",
    "\n",
    "**Question 1.)** Implement Naive Bayes using `sklearn.naive_bayes.MultinomialNB`. Train on the training set and evaluate accuracy on the test set using `.predict(...)`. \n",
    "\n",
    "Your model should train almost instantly, and score 82.21% - not bad! On SST, this is actually a very strong baseline.\n",
    "\n",
    "Recall that Naive Bayes can be interpreted as a linear model, where score is given by:\n",
    "\n",
    "$$ \\mathrm{score}(x) = \\log \\left(\\frac{P(y = 1) \\prod_{j=1}^n P(x_j | y = 1)}{P(y = 0) \\prod_{j=1}^n P(x_j | y = 0)}\\right) \n",
    "= \\left( \\log\\hat{\\theta}_1 - \\log\\hat{\\theta}_0 \\right) + \\sum_{j=1}^n \\left( \\log\\hat{\\theta}_{1,j} - \\log\\hat{\\theta}_{0,j} \\right)$$\n",
    "\n",
    "You can access the values $\\log\\hat{\\theta}_{k,j}$ from the trained model using `nb.feature_log_prob_[k,j]`.\n",
    "\n",
    "**Question 2.)** In the cell below, compute the weights $w_j = \\left( \\log\\hat{\\theta}_{1,j} - \\log\\hat{\\theta}_{0,j} \\right)$ of the linear model, and find the top 10 most negative and most positive weights. _(Hint: use `np.argsort` to get the indices of the most extreme elements.)_ Do the features you found make sense for this domain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer for Part (b).2\n",
    "<a id=\"answers_b2\"></a>\n",
    "\n",
    "**2.)** _Your answer here!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "#### YOUR CODE HERE ####\n",
    "# Code for part (b).1\n",
    "nb = MultinomialNB()\n",
    "\n",
    "\n",
    "#### END(YOUR CODE) ####\n",
    "acc = accuracy_score(test_y, y_pred)\n",
    "print(\"Accuracy on test set: {:.02%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "# Code for part (b).2\n",
    "linear_weights = None  # populate this with actual values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### END(YOUR CODE) ####\n",
    "\n",
    "print(\"Most negative features:\")\n",
    "for idx in top_negative_features:\n",
    "    print(\"  {:s} ({:.02f})\".format(ds.vocab.id_to_word[idx], \n",
    "                                    linear_weights[idx]))\n",
    "print(\"\")\n",
    "print(\"Most positive features:\")\n",
    "for idx in top_positive_features:\n",
    "    print(\"  {:s} ({:.02f})\".format(ds.vocab.id_to_word[idx], \n",
    "                                    linear_weights[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part (c): Examining Negation\n",
    "\n",
    "While Naive Bayes performs well in the aggregate, as a linear model it's still limited in its ability to model complex phenomena in the data. Each feature - in this case, each word - contributes a weight to the total, and if the sum is $\\ge 0$ we predict the example is positive. But what happens when we have an example with both positive and negative words? For instance:\n",
    "\n",
    "```\n",
    "[Brando 's performance fell short of the high standards set by his earlier work .]\n",
    "[A thoughtful look at a painful incident that made headlines in 1995 .]\n",
    "```\n",
    "\n",
    "Run the cell below to evaluate your model on these examples. It should predict both as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\"Brando 's performance fell short of the high standards set by his earlier work .\",\n",
    "            \"A thoughtful look at a painful incident that made headlines in 1995 .\"]\n",
    "id_lists = [ds.vocab.words_to_ids(ds.canonicalize(s.split())) for s in examples]\n",
    "x = utils.id_lists_to_sparse_bow(id_lists, ds.vocab.size)\n",
    "print(x.shape)\n",
    "nb.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (c).1\n",
    "<a id=\"answers_c1\"></a>\n",
    "\n",
    "**Question 1.)** Why does the model get the first example wrong? Why does it get the second one correct, despite the presence of the words \"painful\" and \"incident\"?\n",
    "\n",
    "**1.)** _Your answer here!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always important to look at individual examples, but let's try to do this a bit more systematically. Recall that SST gives us labels not only at the whole-sentence (root) level, but for individual phrases as well. We can use this to look for examples where polarity changes between different parts of the sentence. Here's one of the examples above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.test_trees[210]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will comb through the test set, looking for examples where there's some degree of ambiguity. We'll use a fairly crude heuristic for now: count up all the non-neutral phrases for a given sentence, and look at ones where there's a mix of both positive and negative labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds.test\n",
    "\n",
    "gb = df.groupby(by=['root_id'])\n",
    "interesting_ids = []   # root ids, index into ds.test_trees\n",
    "interesting_idxs = []  # DataFrame indices, index into ds.test\n",
    "# This groups the DataFrame by sentence\n",
    "for root_id, idxs in gb.groups.items():\n",
    "    # Get the average score of all the phrases for this sentence\n",
    "    mean = df.loc[idxs].label.mean()\n",
    "    if (mean > 0.4 and mean < 0.6):\n",
    "        interesting_ids.append(root_id)\n",
    "        interesting_idxs.extend(idxs)\n",
    "        \n",
    "print(\"Found {:,} interesting examples\".format(len(interesting_ids)))\n",
    "# This will extract only the \"interesting\" sentences we found above\n",
    "test_x_interesting, test_y_interesting = ds.as_sparse_bow(\"test\", root_only=True, \n",
    "                                                          df_idxs=interesting_idxs)\n",
    "print(\"Interesting ids (into ds.test_trees): \", interesting_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (c) continued\n",
    "\n",
    "Answer the following in the cells below.\n",
    "\n",
    "**Question 2.)** Examine a few of the \"interesting\" trees. What kinds of patterns do you see? What is the relation of the polarity of the sub-phrases to that of the whole sentence? Is this well-captured by a linear model?\n",
    "\n",
    "**Question 3.)** Evaluate your model on `test_x_interesting` and compute accuracy. Does your model do better or worse on this slice of the data than on the rest of the test set? What is the _relative_ change in the error rate? _(For example, if you go from 90% accuracy to 85%, that's a 50% increase in error!)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers for Part (c).2 and 3\n",
    "<a id=\"answers_c23\"></a>\n",
    "\n",
    "**2.)** _Your answer here!_\n",
    "\n",
    "**3.)** _Your answer here!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "# Code for part (c).2\n",
    "# Example: display(ds.test_trees[idx])\n",
    "\n",
    "\n",
    "#### END(YOUR CODE) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "# Code for part (c).3\n",
    "acc = 0.0  # replace this with a real value for accuracy\n",
    "\n",
    "\n",
    "#### END(YOUR CODE) ####\n",
    "print(\"Accuracy on selected examples: {:.02f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
